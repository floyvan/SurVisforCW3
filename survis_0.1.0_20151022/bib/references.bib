@article{dehpanah2021,
  abstract = {Competitive online games use rating systems to match players with similar skills to ensure a satisfying experience for players. In this paper, we focus on the importance of addressing different aspects of playing behavior when modeling players for creating match-ups. To this end, we engineer several behavioral features from a dataset of over 75,000 battle royale matches and create player models based on the retrieved features. We then use the created models to predict ranks for different groups of players in the data. The predicted ranks are compared to those of three popular rating systems. Our results show the superiority of simple behavioral models over mainstream rating systems. Some behavioral features provided accurate predictions for all groups of players while others proved useful for certain groups of players. The results of this study highlight the necessity of considering different aspects of the player’s behavior such as goals, strategy, and expertise when making assignments.},
  address = {Las Vegas, NV, USA},
  author = {Dehpanah, A. and Ghori, M.F. and Gemmell, J. and Mobasher, B.},
  booktitle = {2021 International Conference on Computational Science and Computational Intelligence (CSCI)},
  doi = {10.1109/CSCI54926.2021.00160},
  keywords = {type:AI in Player Interaction, Scientific computing, Computational modeling, Games, Predictive models, Data models, Behavioral sciences, Computational intelligence, rank prediction, player modeling, behavioral features, online games},
  month = {December},
  number = {},
  pages = {569--574},
  title = {Player modeling using behavioral signals in competitive online games},
  url = {https://doi.org/10.1109/CSCI54926.2021.00160.},
  volume = {},
  year = {2021}
}

@article{kumaran2023,
  abstract = {Creating engaging interactive story-based experiences dynamically responding to individual player choices poses significant challenges for narrative-centered games. Recent advances in pre-trained large language models (LLMs) have the potential to revolutionize procedural content generation for narrative-centered games. Historically, interactive narrative generation has specified pivotal events in the storyline, often utilizing planning-based approaches toward achieving narrative coherence and maintaining the story arc. However, manual authorship is typically used to create detail and variety in non-player character (NPC) interaction to specify and instantiate plot events. This paper proposes SCENECRAFT, a narrative scene generation framework that automates NPC interaction crucial to unfolding plot events. SCENECRAFT interprets natural language instructions about scene objectives, NPC traits, location, and narrative variations. It then employs large language models to generate game scenes aligned with authorial intent. It generates branching conversation paths that adapt to player choices while adhering to the author’s interaction goals. LLMs generate interaction scripts, semantically extract character emotions and gestures to align with the script, and convert dialogues into a game scripting language. The generated script can then be played utilizing an existing narrative-centered game framework. Through empirical evaluation using automated and human assessments, we demonstrate SCENECRAFT’s effectiveness in creating narrative experiences based on creativity, adaptability, and alignment with intended author instructions.},
  author = {Kumaran, Vikram and Rowe, Jonathan and Mott, Bradford and Lester, James},
  doi = {10.1609/aiide.v19i1.27504},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  keywords = {type:AI in Content Generation, Procedural Content Generation, Interactive Storytelling, Large Language Models},
  month = {Oct.},
  number = {1},
  pages = {86-96},
  title = {SceneCraft: Automating Interactive Narrative Scene Generation in Digital Games with Large Language Models},
  url = {https://ojs.aaai.org/index.php/AIIDE/article/view/27504},
  volume = {19},
  year = {2023}
}

@article{pfau2020,
  abstract = {Balancing the options available to players in a way that ensures rich variety and viability is a vital factor for the success of any video game, and particularly competitive multiplayer games. Traditionally, this balancing act requires extensive periods of expert analysis, play testing and debates. While automated gameplay is able to predict outcomes of parameter changes, current approaches mainly rely on heuristic or optimal strategies to generate agent behavior. In this paper, we demonstrate the use of deep player behavior models to represent a player population (n},
  author = {Pfau, Johannes and Liapis, Antonios and Volkmar, Georg and Yannakakis, Georgios N. and Malaka, Rainer},
  booktitle = {2020 IEEE Conference on Games (CoG)},
  doi = {10.1109/CoG47356.2020.9231958},
  keywords = {type:AI in Game Development and Testing, Games, Decision making, Statistics, Sociology, Computer bugs, Media, Measurement, Automated game testing, balancing, deep learning, generative player modeling, imitation learning, video games},
  month = {August},
  number = {},
  pages = {431-438},
  title = {Dungeons & replicants: Automated game balancing via deep player behavior modeling},
  url = {https://ieeexplore.ieee.org/document/9231958},
  volume = {},
  year = {2020}
}

@article{pricop2024,
  abstract = {This paper explores advanced music generation through hybrid models combining deep neural networks, machine learning algorithms, variational autoencoders (VAEs), long short-term memory (LSTM) networks, and Transformers to create diverse and engaging musical experiences. Our research aims to advance the understanding of music’s impact on our lives and develop methodologies to create diverse and engaging musical experiences tailored to individual preferences. We begin by extracting relevant features from a large and diverse collection of music samples from different genres. These features, encompassing spectral properties, rhythmic patterns, and tonal characteristics, serve as the foundation for our generation models. To generate music, we explore the potential of VAEs, LSTMs, and Transformers, each offering unique capabilities for handling different aspects of the task. VAEs are employed to learn a continuous latent space representation of the music samples, enabling the generation of novel compositions within a specified genre. LSTMs and Transformers, on the other hand, are used to model the temporal dependencies and intricate patterns inherent in music. While not claiming state-of-the-art performance, our approach demonstrates promising outcomes in generation tasks, showcasing its potential to enhance music-related applications such as recommendation systems and creative tools for composers.},
  author = {Tudor-Constantin Pricop and Adrian Iftene},
  doi = {10.1016/j.procs.2024.09.692},
  issn = {1877-0509},
  journal = {Procedia Computer Science},
  keywords = {type:AI in Content Generation, Deep neural networks, machine learning algorithms, variational autoencoders, long short-term memory networks, transformer},
  note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
  pages = {1855-1864},
  title = {Music generation with machine learning and deep neural networks},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050924027522},
  volume = {246},
  year = {2024}
}

@article{rani2023,
  abstract = {The objective of this research is to design the deep reinforcement neural learning-based model that detects the bugs in a game environment. The model automates the bug detection and minimizes human intervention. It makes effective use of the Deep-Q-Network to design and develop the model ‘RLBGameTester’ for measuring the high dimensional sensory inputs. The model modifies the environment to intercept the game screen. It also adds faults to the game before submitting it to the Deep-Q-Network. It calculates the values of the loss function at different iterations. The differences in the values of the loss functions in a bug-free and the bug containing game environment point out the presence of a bug. It also locates the position where the bug appears. The proposed model is useful for multiple game environments with minimum customization. Its applicability for blurred as well as non-blurred inputs at different platforms proves its efficacy. Employing this model may prove a game changer in the game designing industry.},
  author = {Rani, G. and Pandey, U. and Wagde, A.A. and Dhaka, V.S.},
  doi = {10.1007/s41870-022-01047-z},
  journal = {International Journal of Information Technology},
  keywords = {type:AI in Game Development and Testing, Deep-Q-Network, Reinforcement learning, Bug, Testing, Deep learning, Neural network},
  pages = {355-367},
  title = {A deep reinforcement learning technique for bug detection in video games},
  url = {https://doi.org/10.1007/s41870-022-01047-z},
  volume = {15},
  year = {2023}
}

@article{schrittwieser2020,
  abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess1 and Go2, where a perfect simulator is available. However, in real-world problems, the dynamics governing the environment are often complex and unknown. Here we present the MuZero algorithm, which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. The MuZero algorithm learns an iterable model that produces predictions relevant to planning: the action-selection policy, the value function and the reward. When evaluated on 57 different Atari games3—the canonical video game environment for testing artificial intelligence techniques, in which model-based planning approaches have historically struggled4—the MuZero algorithm achieved state-of-the-art performance. When evaluated on Go, chess and shogi—canonical environments for high-performance planning—the MuZero algorithm matched, without any knowledge of the game dynamics, the superhuman performance of the AlphaZero algorithm5 that was supplied with the rules of the game.},
  author = {Schrittwieser, J., Antonoglou, I., Hubert, T. and others},
  doi = {10.1038/s41586-020-03051-4},
  journal = {Nature},
  keywords = {type:AI in Gameplay},
  number = {7839},
  pages = {604--609},
  title = {Mastering Atari, Go, chess and shogi by planning with a learned model},
  url = {https://www.nature.com/articles/s41586-020-03051-4},
  volume = {588},
  year = {2020}
}

@article{servat2023,
  abstract = {Research has shown that enhancing the believability of non-player characters (NPCs) in video games can increase player immersion. Traditionally, NPCs have been implemented with predefined behaviors through rigid coding. However, this approach leads to monotonous and repetitive actions as NPCs rigidly follow their programming, which affects their believability. Furthermore, the recent shift from 2D to 3D and first-person games has underscored the importance of believable NPCs. Therefore, it is essential to explore alternative methods for creating NPCs that can overcome the limitations of traditional approaches. Emerging artificial intelligence techniques, particularly machine learning and reinforcement learning, offer promising opportunities to replace traditional NPC development methods as NPC believability becomes increasingly important. In this study, we trained a shooter NPC using a deep reinforcement learning algorithm and compared it to another NPC that had the same goal but was developed using hard-coded instructions. The test results for both NPCs show that the model trained with reinforcement learning exhibits more realistic shooting behavior.},
  author = {Servat, A. and Mohamadi, H.S.},
  booktitle = {2023 International Conference on Electrical, Computer and Communication (ICECC)},
  doi = {10.1109/ISGS61252.2023.10559740},
  keywords = {type:AI in Player Interaction, Video games, Three-dimensional displays, Machine learning algorithms, Programming, Deep reinforcement learning, Encoding, Serious games, believablility, Immersion, NPCs, machine learning, video games},
  month = {March},
  number = {},
  pages = {1-5},
  title = {Immersive game worlds: Using deep reinforcement learning for lifelike non-player characters},
  url = {https://ieeexplore.ieee.org/document/10559740},
  volume = {},
  year = {2023}
}

@article{sousa2022,
  abstract = {This article shows the intimate relationship between Artificial Intelligence (AI) and video games research in 13 categories of analysis based on a bibliometric survey carried out in the Scopus database. We first briefly reviewed the relation between video games and AI. Then, we introduced the methodology of literature collection, presented and discussed the query, as well the flow of data treatment in the applications and plugins used. Since the article is concerned with a historical point of view of the relationship between digital games and AI the results were many and, therefore, we focused on the top 10 of each ranking, and discussed these results separately. Finally, we discuss the limitations of our review, proposing future research directions for scholars.},
  author = {Sousa, J.P. and Gomes, J.P. and Tavares, R.J.C.},
  doi = {10.1016/j.procs.2022.08.038},
  journal = {Procedia Computer Science},
  keywords = {type:Surveys and Reviews, Computer games, AI, Games, Bibliometric analysis, Virtual Reality},
  pages = {315--323},
  title = {Review and analysis of research on video games and artificial intelligence: A look back and a step forward},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050922007761},
  volume = {204},
  year = {2022}
}

@article{summerville2018,
  abstract = {This survey explores procedural content generation via machine learning (PCGML), defined as the generation of game content using machine learning models trained on existing content. As the importance of PCG for game development increases, researchers explore new avenues for generating high-quality content with or without human involvement; this paper addresses the relatively new paradigm of using machine learning (in contrast with search-based, solver-based, and constructive methods). We focus on what is most often considered functional game content, such as platformer levels, game maps, interactive fiction stories, and cards in collectible card games, as opposed to cosmetic content, such as sprites and sound effects. In addition to using PCG for autonomous generation, cocreativity, mixed-initiative design, and compression, PCGML is suited for repair, critique, and content analysis because of its focus on modeling existing content. We discuss various data sources and representations that affect the generated content. Multiple PCGML methods are covered, including neural networks: long short-term memory networks, autoencoders, and deep convolutional networks; Markov models: n-grams and multi-dimensional Markov chains; clustering; and matrix factorization. Finally, we discuss open problems in PCGML, including learning from small data sets, lack of training data, multilayered learning, style-transfer, parameter tuning, and PCG as a game mechanic.},
  author = {Summerville, A. and others},
  doi = {10.1109/TG.2018.2846639},
  journal = {IEEE Transactions on Games},
  keywords = {type:AI in Content Generation, Games, Machine learning, Training, Machine learning algorithms, Neural networks, Maintenance engineering, Media, Computational and artificial intelligence, design tools, electronic design methodology, knowledge representation, machine learning;pattern analysis, procedural content generation (PCG)},
  number = {3},
  pages = {257--270},
  title = {Procedural content generation via machine learning (PCGML)},
  url = {https://ieeexplore.ieee.org/document/8382283},
  volume = {10},
  year = {2018}
}

@article{vinyals2019,
  abstract = {Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8% of officially ranked human players.},
  author = {Vinyals, O., Babuschkin, I., Czarnecki, W.M. and others},
  doi = {10.1038/s41586-019-1724-z},
  journal = {Nature},
  keywords = {type:AI in Gameplay},
  number = {7822},
  pages = {350-354},
  title = {Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  url = {https://doi.org/10.1038/s41586-019-1724-z},
  volume = {575},
  year = {2019}
}

